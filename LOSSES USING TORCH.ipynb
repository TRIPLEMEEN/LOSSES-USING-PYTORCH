{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "#Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))\n",
    "                              ])\n",
    "\n",
    "#Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download = True, train = True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 64, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3244, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10))\n",
    "\n",
    "#Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "#Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "#Forward pass, get our logits\n",
    "logits = model(images)\n",
    "#Calculate the loss with the logits and the labels\n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3295, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#ALTERNATIVEY USING LOGSOFTMAX\n",
    "\n",
    "#TODO: Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "\n",
    "#Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "#Get our data\n",
    "images, labels = next(iter(trainloader))\n",
    "#Flatten images\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "#Forward pass, get our logits\n",
    "logps = model(images)\n",
    "#Calculate the loss with the logits and the labels\n",
    "loss = criterion(logps, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USING LOSS TO PERFORM BACKPROP\n",
    "    \n",
    " #AUTOGRAD   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2585,  1.2872],\n",
      "        [-0.3888, -1.5620]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.5838, 1.6569],\n",
      "        [0.1511, 2.4397]], grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x**2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PowBackward0 object at 0x000001CB60AB0400>\n"
     ]
    }
   ],
   "source": [
    "##grad_fn shows the function that generated this variable\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4579, grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "z = y.mean()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6292,  0.6436],\n",
      "        [-0.1944, -0.7810]])\n",
      "tensor([[ 0.6292,  0.6436],\n",
      "        [-0.1944, -0.7810]], grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print(x.grad)\n",
    "print(x/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOSS AND AUTOGRAD TOGETHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "logps = model(images)\n",
    "loss = criterion(logps, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[-0.0025, -0.0025, -0.0025,  ..., -0.0025, -0.0025, -0.0025],\n",
      "        [-0.0020, -0.0020, -0.0020,  ..., -0.0020, -0.0020, -0.0020],\n",
      "        [ 0.0055,  0.0055,  0.0055,  ...,  0.0055,  0.0055,  0.0055],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0002,  0.0002,  0.0002,  ...,  0.0002,  0.0002,  0.0002],\n",
      "        [-0.0020, -0.0020, -0.0020,  ..., -0.0020, -0.0020, -0.0020]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# USING LOSSES FOR GRADIENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "#Optimizers require the parameters to optimize and a learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[-0.0222,  0.0309,  0.0056,  ..., -0.0331,  0.0185, -0.0335],\n",
      "        [-0.0303,  0.0000,  0.0221,  ...,  0.0028, -0.0091,  0.0185],\n",
      "        [ 0.0211, -0.0175,  0.0203,  ..., -0.0071, -0.0288, -0.0012],\n",
      "        ...,\n",
      "        [ 0.0281, -0.0164, -0.0083,  ...,  0.0192, -0.0124,  0.0196],\n",
      "        [ 0.0175,  0.0046,  0.0052,  ..., -0.0261, -0.0247,  0.0245],\n",
      "        [-0.0085, -0.0058, -0.0122,  ...,  0.0213,  0.0274,  0.0273]],\n",
      "       requires_grad=True)\n",
      "Gradient -  tensor([[ 0.0015,  0.0015,  0.0015,  ...,  0.0015,  0.0015,  0.0015],\n",
      "        [-0.0031, -0.0031, -0.0031,  ..., -0.0031, -0.0031, -0.0031],\n",
      "        [-0.0027, -0.0027, -0.0027,  ..., -0.0027, -0.0027, -0.0027],\n",
      "        ...,\n",
      "        [ 0.0014,  0.0014,  0.0014,  ...,  0.0014,  0.0014,  0.0014],\n",
      "        [-0.0014, -0.0014, -0.0014,  ..., -0.0014, -0.0014, -0.0014],\n",
      "        [-0.0009, -0.0009, -0.0009,  ..., -0.0009, -0.0009, -0.0009]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "#Clear the gradients, do this because gradients are accumulated \n",
    "optimizer.zero_grad()\n",
    "\n",
    "#Forward pass, then backward pass, then update weights\n",
    "output = model.forward(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradient - ', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights -  Parameter containing:\n",
      "tensor([[-0.0222,  0.0309,  0.0056,  ..., -0.0331,  0.0185, -0.0335],\n",
      "        [-0.0302,  0.0000,  0.0222,  ...,  0.0029, -0.0090,  0.0185],\n",
      "        [ 0.0211, -0.0174,  0.0203,  ..., -0.0071, -0.0288, -0.0012],\n",
      "        ...,\n",
      "        [ 0.0281, -0.0164, -0.0083,  ...,  0.0192, -0.0124,  0.0196],\n",
      "        [ 0.0175,  0.0046,  0.0052,  ..., -0.0261, -0.0246,  0.0245],\n",
      "        [-0.0084, -0.0058, -0.0122,  ...,  0.0213,  0.0274,  0.0273]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#Take an update step and few the new weights\n",
    "optimizer.step()\n",
    "print('Updated weights - ', model[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.911112698283531\n",
      "Training loss: 0.8539943133018164\n",
      "Training loss: 0.5221179793320739\n",
      "Training loss: 0.42942634628398585\n",
      "Training loss: 0.3858630028583093\n"
     ]
    }
   ],
   "source": [
    "#Actaul Training Solution\n",
    "\n",
    "model = nn.Sequential(nn.Linear(784,128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim=1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.003)\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        #Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        \n",
    "        #TODO: Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import helper\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "#Turn off gradients to speed up this part\n",
    "with torch.no_grad():\n",
    "    logits = model.forward(img)\n",
    "    \n",
    "#Output of the network are logits, need to take softmax for probabilities\n",
    "ps = F.softmax(logits, dim =1)\n",
    "helper.view_classify(img.view(1, 28, 28), ps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
